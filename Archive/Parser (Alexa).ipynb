{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/us bbbr/bin/env python\n",
    "\n",
    "#for search\n",
    "from googlesearch import search\n",
    "import csv\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "#add article text1\n",
    "from newspaper import Article\n",
    "\n",
    "#add article text2\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "#file creation\n",
    "now = datetime.datetime.now()\n",
    "name = now.strftime(\"%m%d%Y%H%M%S\")\n",
    "file_name = \"output_alexa\" + name + \".csv\"\n",
    "print(file_name) \n",
    "with open(file_name, \"a\", newline='') as w:\n",
    "            writer = csv.writer(w)\n",
    "            row = [\"query_id\", \"query\", \"result position\", \"url\", \"article_text1\", \"article_text2\"]\n",
    "            print(row)\n",
    "            writer.writerow(row)\n",
    "\n",
    "#array with search queries\n",
    "array_of_q = []\n",
    "with open(\"Keywords - Sample.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        array_of_q.append(row[1]+query_suffix)\n",
    "print(array_of_q)\n",
    "\n",
    "#search and results write\n",
    "num_id = 1\n",
    "for i in array_of_q:\n",
    "    num = 0\n",
    "    for url in search(i, tld='com', lang='en', stop=5, pause=random.randint(1,3)):\n",
    "        num += 1\n",
    "        with open(file_name, \"a\", newline='', encoding='utf-8') as w:\n",
    "            writer = csv.writer(w)\n",
    "                #get article text1\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.html\n",
    "            article.parse()\n",
    "                #get article text2\n",
    "            html = urllib.request.urlopen(url).read()\n",
    "                #write results\n",
    "            row = [str(num_id), str(i), str(num), str(url), str(article.text),str(text_from_html(html))]\n",
    "            print(row)\n",
    "            writer.writerow(row)\n",
    "    num_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

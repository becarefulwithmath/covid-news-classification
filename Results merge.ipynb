{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6593\n",
      "17 remained\n",
      "16 remained\n",
      "15 remained\n",
      "14 remained\n",
      "13 remained\n",
      "12 remained\n",
      "11 remained\n",
      "10 remained\n",
      "9 remained\n",
      "8 remained\n",
      "7 remained\n",
      "6 remained\n",
      "5 remained\n",
      "4 remained\n",
      "3 remained\n",
      "2 remained\n",
      "1 remained\n",
      "0 remained\n",
      "                                                  url  \\\n",
      "0   https://sunnybrook.ca/research/media/item.asp?...   \n",
      "1   https://www.cdc.gov/coronavirus/2019-nCoV/summ...   \n",
      "2   https://theconversation.com/coronavirus-and-ca...   \n",
      "3   https://www.abc.net.au/news/2020-06-28/world-r...   \n",
      "4   https://www.medrxiv.org/content/10.1101/2020.0...   \n",
      "5   https://www.cdc.gov/coronavirus/2019-ncov/prev...   \n",
      "6   https://www.dailysabah.com/life/health/how-ris...   \n",
      "7   https://www.nytimes.com/2020/06/24/health/coro...   \n",
      "8   https://www.cdc.gov/coronavirus/2019-ncov/need...   \n",
      "9   https://www.cdc.gov/diabetes/managing/flu-sick...   \n",
      "10         https://www.cdc.gov/heartdisease/index.htm   \n",
      "11  https://www.cdc.gov/healthyweight/assessing/bm...   \n",
      "12  https://www.cdc.gov/diabetes/managing/problems...   \n",
      "13  https://www.businessinsider.com/riskiest-to-le...   \n",
      "14           https://www.bbc.com/news/health-52849691   \n",
      "15  https://theconversation.com/americans-disagree...   \n",
      "\n",
      "                                                 text  \n",
      "0   A team of researchers from Sunnybrook, McMaste...  \n",
      "1                                                 nan  \n",
      "2              Editions    Africa  Australia  Cana...  \n",
      "3        Skip to main content ABC News Homepage Se...  \n",
      "4           Skip to main content                  ...  \n",
      "5                                                S...  \n",
      "6   Most of the world, including Turkey, has start...  \n",
      "7   Scientists in Britain announced a major breakt...  \n",
      "8                                               Sk...  \n",
      "9                              Skip directly to si...  \n",
      "10                                 Skip directly t...  \n",
      "11                                 Skip directly t...  \n",
      "12                           Skip directly to site...  \n",
      "13                                         The wor...  \n",
      "14          Homepage Accessibility links Skip to c...  \n",
      "15             Editions    Africa  Australia  Cana...  \n",
      "output_merged06302020165845.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "#get the latest file with output_google* prefix\n",
    "list_of_files = glob.glob('output_google*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#print(latest_file)\n",
    "df_g = pd.read_csv(latest_file)\n",
    "df_g=df_g[['url','article_text1','article_text2']]\n",
    "df_g.columns = ['url','text 1','text 2']\n",
    "#print(df_g)\n",
    "\n",
    "#get the latest file with output_alexa* prefix\n",
    "list_of_files = glob.glob('output_alexa*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#print(latest_file)\n",
    "df_a = pd.read_csv(latest_file)\n",
    "#print(df_a)\n",
    "\n",
    "\n",
    "\n",
    "#merging files and remove duplicates\n",
    "df3 = df_a\n",
    "df3=pd.concat([df3,df_g], sort = True, ignore_index=True)\n",
    "\n",
    "#df3.assign(Len1=len(df3['text 1']))\n",
    "#df.assign(Len1=df['temp_c'] * 9 / 5 + 32)\n",
    "#df3['len1']=len(df3.at[5,'text 1'])\n",
    "df3['len1'] = 0\n",
    "df3['len2'] = 0\n",
    "df3['text'] = \"\"\n",
    "\n",
    "print(len(str(df3.at[3,'text 1'])))\n",
    "counter = 0\n",
    "while counter <= len(df3)-1:\n",
    "    #print(text1(array_links.iloc[counter][0]))\n",
    "    #print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "    #df2.set_value(counter,'text 1',1)\n",
    "    len1=len(str(df3.at[counter,'text 1']))\n",
    "   # text11=str(df3.at[counter,'text 1'])\n",
    "   # text22=str(df3.at[counter,'text 2'])\n",
    "    df3.at[counter,'len1'] = len1\n",
    "    len2=len(str(df3.at[counter,'text 2']))\n",
    "    df3.at[counter,'len2'] = len2\n",
    "    if len1>len2:\n",
    "        df3.at[counter,'text'] = str(df3.at[counter,'text 1'])\n",
    "    else:\n",
    "        df3.at[counter,'text'] = str(df3.at[counter,'text 2'])\n",
    "    counter += 1\n",
    "    print(str(len(df3)-counter)+' remained')\n",
    "#df3.columns = ['url','text 1','text 2','len1','len2','text']\n",
    "df3=df3.drop_duplicates(['url'])\n",
    "del df3['text 1']\n",
    "del df3['text 2']\n",
    "del df3['len1']\n",
    "del df3['len2']\n",
    "#df3.drop(columns=['text 1', 'text 2', 'len1', 'len1'], axis=1)\n",
    "print(df3)\n",
    "\n",
    "#file creation\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "name = now.strftime(\"%m%d%Y%H%M%S\")\n",
    "file_name = \"output_merged\" + name + \".csv\"\n",
    "df3.to_csv(file_name, index = False)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

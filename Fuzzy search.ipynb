{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#fuzzy search\\nfrom fuzzywuzzy import process\\n#str2Match = \"apple inc\"\\n#strOptions = [\"Apple Inc.\",\"apple park\",\"apple incorporated\",\"iphone\"]\\nstr2Match = df_m.at[5, \\'text\\']\\nstrOptions = keywords\\nRatios = process.extract(str2Match,strOptions)\\nprint(Ratios)\\nprint (type(Ratios)) \\n# You can also select the string with the highest matching percentage\\nhighest = process.extractOne(str2Match,strOptions)\\nprint(highest)\\nprint (type(highest)) '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#get the latest file with output_merged* prefix\n",
    "list_of_files = glob.glob('output_merged*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#print(latest_file)\n",
    "df_m = pd.read_csv(latest_file)\n",
    "df_m = df_m.drop_duplicates(['url'])\n",
    "#print(df3)\n",
    "\n",
    "#read list of biases and keywords\n",
    "df_b = pd.read_csv('Bias indicators.csv')\n",
    "#print(df_b_i)\n",
    "\n",
    "#populate df_m\n",
    "\n",
    "n_width=10\n",
    "\n",
    "#keywords\n",
    "ini_list = df_b.at[0, 'keywords']\n",
    "keywords = ini_list.strip('][').split('; ')\n",
    "#print(keywords)\n",
    "\n",
    "#import needed for keywords search\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text\n",
    "\n",
    "#loop1 - creation of headers\n",
    "counter_url = 0\n",
    "while counter_url <= len(df_m)-1:\n",
    "    counter_bias = 0\n",
    "    while counter_bias <= len(df_b)-1:\n",
    "        bias_column_name=df_b.at[counter_bias, 'bias']\n",
    "        df_m[bias_column_name] = ''\n",
    "        counter_bias += 1\n",
    "    counter_url += 1\n",
    "    #print(str(len(df_m)-counter_url)+' remained')\n",
    "    \n",
    "#function text cleaning\n",
    "new_line = ' XXX '\n",
    "other_replacer = ' xxxxxxxxx '\n",
    "def text_cleaning(raw_text: str) -> str:\n",
    "    raw_text = raw_text.replace('no matches','')\n",
    "    raw_text = raw_text.replace('\\n', new_line)\n",
    "    counter_i = 0\n",
    "    while counter_i <= 50:\n",
    "        raw_text = raw_text.replace('Displaying '+str(counter_i)+' of '+str(counter_i)+' matches:',other_replacer)\n",
    "        counter_i = counter_i + 1\n",
    "    if len(raw_text) < 10:\n",
    "      raw_text = ''\n",
    "    elif 1 == 1:\n",
    "      a = 1\n",
    "    raw_text = raw_text.replace(other_replacer+new_line, '')\n",
    "    return raw_text   \n",
    "\n",
    "#loop2 - cell population\n",
    "counter_url = 0\n",
    "while counter_url <= len(df_m)-1:\n",
    "    counter_bias = 0\n",
    "    while counter_bias <= len(df_b)-1:\n",
    "        bias_column_name=df_b.at[counter_bias, 'bias']\n",
    "        #print(bias_column_name)\n",
    "        results_string = '' #to be populated\n",
    "        results_list = [] #to be populated\n",
    "        #print(results_array)\n",
    "        #define keywords\n",
    "        ini_list = df_b.at[counter_bias, 'keywords']\n",
    "        keywords = ini_list.strip('][').split('; ')\n",
    "        #print(keywords)\n",
    "        for keyword in keywords:\n",
    "            #test_counter = test_counter+1\n",
    "            #start search\n",
    "            text = nltk.Text(nltk.word_tokenize(str(df_m.at[counter_url, 'text'])))\n",
    "            match = text.concordance(str(keyword), width = n_width, lines=30) #our result\n",
    "            sys.stdout = open('file', 'w', encoding = 'utf-8')\n",
    "            file = open('file', 'r', encoding = 'utf-8')\n",
    "            results = file.read()\n",
    "            results_string = results_string + text_cleaning(results)\n",
    "            #print(type(match))\n",
    "            #results_list.extend(match)\n",
    "            #print(results_list)\n",
    "        #results write    \n",
    "        df_m.at[counter_url,bias_column_name] = results_string\n",
    "        #df_m.at[counter_url,bias_column_name] = counter_url+counter_bias+test_counter\n",
    "        counter_bias += 1\n",
    "    #len1=len(str(df3.at[counter,'text 1']))\n",
    "   # text11=str(df3.at[counter,'text 1'])\n",
    "   # text22=str(df3.at[counter,'text 2'])\n",
    "    #df3.at[counter,'len1'] = len1\n",
    "    counter_url += 1\n",
    "    #print(str(len(df_m)-counter_url)+' remained')\n",
    "\n",
    "#file creation\n",
    "#print(df_m)\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "name = now.strftime(\"%m%d%Y%H%M%S\")\n",
    "file_name = \"output_fuzzy_search\" + name + \".csv\"\n",
    "df_m.to_csv(file_name, index = False)\n",
    "#print(file_name)\n",
    "\n",
    "\"\"\"#fuzzy search\n",
    "from fuzzywuzzy import process\n",
    "#str2Match = \"apple inc\"\n",
    "#strOptions = [\"Apple Inc.\",\"apple park\",\"apple incorporated\",\"iphone\"]\n",
    "str2Match = df_m.at[5, 'text']\n",
    "strOptions = keywords\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "print(Ratios)\n",
    "print (type(Ratios)) \n",
    "# You can also select the string with the highest matching percentage\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "print(highest)\n",
    "print (type(highest)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
